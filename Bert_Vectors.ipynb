{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: tqdm in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from pytorch-pretrained-bert) (4.36.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.17.3)\n",
      "Requirement already satisfied: requests in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2.22.0)\n",
      "Requirement already satisfied: regex in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2019.8.19)\n",
      "Requirement already satisfied: boto3 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.10.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2018.1.18)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.5 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (1.13.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.5->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.5->boto3->pytorch-pretrained-bert) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/shreyas/anaconda3/envs/bert/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.5->boto3->pytorch-pretrained-bert) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape = (566, 3) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768744566203768832</td>\n",
       "      <td>earthquake italy 267 dead hundreds injured</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768822900812046340</td>\n",
       "      <td>dlusvideonews montepulciano damages earthquake...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768848577225428992</td>\n",
       "      <td>italy quake young girl found alive rubble leas...</td>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769138472636469248</td>\n",
       "      <td>new post national disaster italy quake death t...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>769113679073800193</td>\n",
       "      <td>number dead italy quake climbs first funerals ...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  idx                                             tweets  \\\n",
       "0  768744566203768832        earthquake italy 267 dead hundreds injured    \n",
       "1  768822900812046340  dlusvideonews montepulciano damages earthquake...   \n",
       "2  768848577225428992  italy quake young girl found alive rubble leas...   \n",
       "3  769138472636469248  new post national disaster italy quake death t...   \n",
       "4  769113679073800193  number dead italy quake climbs first funerals ...   \n",
       "\n",
       "   labels  \n",
       "0     [2]  \n",
       "1     [2]  \n",
       "2  [0, 3]  \n",
       "3     [2]  \n",
       "4     [2]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from os.path import join, exists\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_json(filename: str,filepath: str = '',date_time_tag: str = '',ext: str = \".json\",\n",
    "              show_path: bool = False) -> OrderedDict:\n",
    "    file_loc = join(filepath,date_time_tag + filename + ext)\n",
    "    if show_path:\n",
    "        print(\"Reading JSON file: [{}]\".format(file_loc))\n",
    "    if exists(join(filepath,date_time_tag + filename + ext)):\n",
    "        try:\n",
    "            with open(file_loc, encoding=\"utf-8\") as file:\n",
    "                json_dict = json.load(file)\n",
    "                json_dict = OrderedDict(json_dict)\n",
    "                # json_dict = OrderedDict(json.load(file))\n",
    "            file.close()\n",
    "            return json_dict\n",
    "        except Exception as e:\n",
    "            print(\"Could not open file as JSON: [{}]. \\n Reason:[{}]\".format(file_loc,e))\n",
    "            with open(file_loc, encoding=\"utf-8\") as file:\n",
    "                json_dict = str(file)\n",
    "                json_dict = json.loads(json_dict)\n",
    "                # json_dict = OrderedDict(json_dict)\n",
    "            return json_dict\n",
    "    else:\n",
    "        print(\"File does not exist at: [{}]\".format(file_loc))\n",
    "        return False\n",
    "\n",
    "def json2df(filename = \"smerp_labeled_validation\",dataset_dir=\"\"):\n",
    "    catid2cattxt_map = load_json(filename=filename,filepath=dataset_dir)\n",
    "    idxs, tweets, labels = [], [], []\n",
    "    for idx in catid2cattxt_map.keys():\n",
    "        idxs.append(idx)\n",
    "        tweets.append(catid2cattxt_map[idx][\"parsed_tweet\"])\n",
    "        labels.append(catid2cattxt_map[idx][\"classes\"])\n",
    "\n",
    "    df = pd.DataFrame.from_dict({\"idx\"    :idxs,\n",
    "                                    \"tweets\"   :tweets,\n",
    "                                    \"labels\":labels})\n",
    "    df = df[~df['tweets'].isna()]\n",
    "    df.to_csv(path_or_buf=join(dataset_dir,filename + \"_df.csv\"))\n",
    "    print(\"Data shape = {} \".format(df.shape))\n",
    "    return df\n",
    "\n",
    "df = json2df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "# Isnt required here as already cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to tokenize input text for cleaning\n",
    "def tokenizer_spacy(input_text: str,remove_stopwords=False):\n",
    "    input_text = spacy_en(input_text)\n",
    "    tokens = []\n",
    "    for token in input_text:\n",
    "        if remove_stopwords and token.text in STOP_WORDS:\n",
    "            continue\n",
    "        tokens.append(token.text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n"
     ]
    }
   ],
   "source": [
    "## Cleaning function\n",
    "import re\n",
    "# all_stops = set(STOP_WORDS) | set(string.punctuation)\n",
    "def clean_txt(txt):\n",
    "    txt = re.sub('[^A-Za-z0-9 ]+', '', txt)\n",
    "    txt = [token for token in tokenizer_spacy(txt) if token.lower() not in STOP_WORDS]\n",
    "    txt = \" \".join(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             earthquake italy 267 dead hundreds injured\n",
       "1      dlusvideonews montepulciano damages earthquake...\n",
       "2      italy quake young girl found alive rubble 240 ...\n",
       "3      new post national disaster italy quake death t...\n",
       "4      number dead italy quake climbs funerals held i...\n",
       "                             ...                        \n",
       "561    urlurl canadian dead italys earthquake canadia...\n",
       "562    dead toll rises italy earthquake 120 reported ...\n",
       "563    mayor amatrice italy says quakedamaged city ne...\n",
       "564    usgs estimated significant casualties likely e...\n",
       "565    death toll italyearthquake 250 365 people inju...\n",
       "Name: tweets, Length: 566, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply cleaning function to input data\n",
    "data[\"txts\"] = data[\"txts\"].apply(clean_txt)\n",
    "logger.debug(type(data[\"txts\"].iloc[0]))\n",
    "logger.debug(data[\"txts\"].iloc[0])\n",
    "logger.debug(data.head())\n",
    "data[\"txts\"].str.replace('\\s{2,}', ' ')  ## Replaces multiple spaces to single\n",
    "data.to_csv(datafile,index=None,header=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spl_tokens(tweets):\n",
    "    return \"[CLS] \" + tweets + \" [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 3)\n",
      "(566, 3)\n",
      "(453, 3)\n"
     ]
    }
   ],
   "source": [
    "## Divide data to train, val and test\n",
    "train_size, val_size = 0.7, 0.1\n",
    "train_df = data[0:int(data.shape[0] * train_size)]\n",
    "print(train_df.shape)\n",
    "val_df = data[int(data.shape[0] * train_size):int(data.shape[0] * (train_size + val_size))]\n",
    "print(val_df.shape)\n",
    "test_df = data[int(data.shape[0] * (train_size + val_size)):int(data.shape[0])]\n",
    "print(test_df.shape)\n",
    "\n",
    "train_df.to_csv('data/XC_GCN_BERT_train.csv', sep=',', index=False, header=True)\n",
    "val_df.to_csv('data/XC_GCN_BERT_val.csv', sep=',', index=False, header=True)\n",
    "test_df.to_csv('data/XC_GCN_BERT_test.csv', sep=',', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare input text for BERT and truncate long text larger than 512 tokens\n",
    "max_seq_length = 512\n",
    "txts_tokens = []\n",
    "txts_segment_ids = []\n",
    "indexed_tokens = []\n",
    "i=0\n",
    "max_len = 0\n",
    "max_tokens = []\n",
    "for txt in train_df[\"txts\"]:\n",
    "    txt_cleaned = add_spl_tokens(txt)\n",
    "    txt_tokens = BERT_tokenizer.tokenize(add_spl_tokens(txt))\n",
    "    if len(txt_tokens) > max_seq_length:\n",
    "        i+=1\n",
    "        if len(txt_tokens) > max_len: \n",
    "            max_len = len(txt_tokens)\n",
    "            max_tokens = txt_tokens\n",
    "        txt_tokens = txt_tokens[:max_seq_length]\n",
    "    txts_tokens.append(txt_tokens)\n",
    "    txt_segment_ids = [1] * len(txt_tokens)\n",
    "    txts_segment_ids.append(txt_segment_ids)\n",
    "    txt_tokens_ids = BERT_tokenizer.convert_tokens_to_ids(txt_tokens)\n",
    "    indexed_tokens.append(txt_tokens_ids)\n",
    "    \n",
    "    padding = [0] * (max_seq_length - len(txt_tokens_ids))\n",
    "    txt_tokens_ids += padding\n",
    "#     input_mask += padding\n",
    "    txt_segment_ids += padding\n",
    "\n",
    "    assert len(txt_tokens_ids) == max_seq_length\n",
    "#     assert len(input_mask) == max_seq_length\n",
    "    assert len(txt_segment_ids) == max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documnets with more than 64 tokens:[0]\n",
      "max_len: [0]\n",
      "max_tokens: [[]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Documnets with more than {} tokens:[{}]\".format(max_seq_length,i))\n",
    "print(\"max_len: [{}]\".format(max_len))\n",
    "print(\"max_tokens: [{}]\".format(max_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 101)\n",
      "('updated', 7172)\n",
      "('italy', 3304)\n",
      "('earthquake', 8372)\n",
      "('250', 5539)\n",
      "('fatalities', 20871)\n",
      "('360', 9475)\n",
      "('injured', 5229)\n",
      "('sis', 24761)\n",
      "('##mo', 5302)\n",
      "('te', 8915)\n",
      "('##mb', 14905)\n",
      "('##lor', 10626)\n",
      "('cnn', 13229)\n",
      "('ur', 24471)\n",
      "('##lu', 7630)\n",
      "('##rl', 12190)\n",
      "('[SEP]', 102)\n"
     ]
    }
   ],
   "source": [
    "for tup in zip(txts_tokens[0], indexed_tokens[0]):\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  7172,  3304,  8372,  5539, 20871,  9475,  5229, 24761,  5302,\n",
      "          8915, 14905, 10626, 13229, 24471,  7630, 12190,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens[0]])\n",
    "segments_tensors = torch.tensor([txts_segment_ids[0]])\n",
    "print(tokens_tensor)\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: [453]\n",
      "Number of batches: [12]\n",
      "Number of tokens: [1]\n",
      "Number of hidden units: [64]\n"
     ]
    }
   ],
   "source": [
    "all_encoded_layers = []\n",
    "for txt_tokens_ids,txt_segment_ids in zip(indexed_tokens,txts_segment_ids):\n",
    "    tokens_tensor = torch.tensor([txt_tokens_ids])\n",
    "    segments_tensors = torch.tensor([txt_segment_ids])\n",
    "#     logger.info(tokens_tensor)\n",
    "#     logger.info(segments_tensors)\n",
    "#     logger.info(tokens_tensor.shape, segments_tensors.shape)\n",
    "    assert tokens_tensor.shape == segments_tensors.shape, \"shape does not match\"\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "        all_encoded_layers.append(encoded_layers)\n",
    "print(\"Number of documents: [{}]\".format(len(all_encoded_layers)))\n",
    "layer_i = 0\n",
    "\n",
    "print(\"Number of layers: [{}]\".format(len(all_encoded_layers[layer_i])))\n",
    "batch_i = 0\n",
    "\n",
    "print(\"Number of tokens: [{}]\".format(len(all_encoded_layers[layer_i][batch_i])))\n",
    "token_i = 0\n",
    "\n",
    "print(\"Number of tokens: [{}]\".format(len(all_encoded_layers[layer_i][batch_i][token_i]),\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_layers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 768])\n",
      "tensor([ 5.1236e-01, -4.9300e-01,  6.2954e-01, -1.0269e-02,  1.2519e+00,\n",
      "         6.0471e-01,  2.3423e-01,  1.9247e-01,  4.4352e-01,  2.5995e-01,\n",
      "        -3.8186e-02,  5.9640e-01,  3.4475e-01,  1.1276e-01, -1.6591e+00,\n",
      "         4.9349e-01, -1.0163e+00,  2.5172e-01, -7.5355e-01, -4.0591e-01,\n",
      "         1.5207e+00, -2.0056e-01,  4.8248e-01,  2.6045e+00, -4.2402e-02,\n",
      "         1.4331e-01,  1.5549e+00, -2.4001e-01,  3.8056e-01, -1.0928e+00,\n",
      "         5.6604e-02, -7.3802e-01,  1.2466e+00, -1.7257e+00, -8.9991e-01,\n",
      "        -1.9250e+00, -2.9613e+00, -7.4195e-01,  1.0127e+00,  9.2177e-02,\n",
      "        -6.7863e-01,  4.6158e-01, -6.9841e-01,  4.0295e-01, -1.7117e-01,\n",
      "         4.6207e-01,  1.2775e+00, -1.6717e+00,  6.3274e-01, -8.7934e-01,\n",
      "        -2.8565e-01, -1.4899e-01,  1.6652e+00, -4.2199e-01,  1.2057e+00,\n",
      "        -1.2272e+00,  3.0324e-01, -5.9583e-01,  6.0381e-01,  3.0766e-01,\n",
      "         5.4924e-01, -8.3224e-01,  1.2049e+00, -1.4595e+00, -1.5858e+00,\n",
      "        -7.3449e-01, -4.3038e-01,  3.9315e-01, -4.4432e-01,  1.0348e+00,\n",
      "         2.0349e-01,  9.3302e-01, -8.8413e-01, -5.2314e-01, -2.7422e-01,\n",
      "         4.3115e-02,  9.0157e-02,  3.8847e-02,  7.1300e-01, -2.2450e-01,\n",
      "        -6.2898e-01, -1.6979e+00, -3.4376e-02, -3.7384e-01,  1.0881e+00,\n",
      "        -1.3819e-01, -1.7305e-01,  3.5141e-01, -5.8171e-01, -1.1109e-01,\n",
      "        -2.6550e-01,  3.3425e-01,  3.0042e-01, -1.0960e-02,  2.3078e-02,\n",
      "         3.2831e-01, -5.1551e-01, -1.7133e-01, -1.1362e+00,  7.7724e-01,\n",
      "         1.9822e+00, -7.0910e-01, -3.4372e-02, -1.5961e+00, -5.2377e-01,\n",
      "        -1.8314e-01,  3.2251e-01, -4.6641e-01, -4.6790e-01, -3.9523e-02,\n",
      "         2.2391e+00,  6.8598e-01, -4.7440e-01, -3.8932e-01,  1.9810e+00,\n",
      "         3.4966e-01, -1.1936e+00, -3.8259e-01, -7.6300e-02, -1.3304e+00,\n",
      "         5.4280e-01, -4.0072e-01, -4.2037e-01,  1.1609e+00, -8.0206e-01,\n",
      "        -6.6500e-01, -1.6157e+00, -6.5420e-02,  2.1381e-01, -6.3510e-01,\n",
      "         1.2867e+00,  1.7237e+00, -1.1723e+00, -1.1943e+00,  1.3337e+00,\n",
      "        -1.0226e+00,  6.3718e-01,  1.7859e-01, -5.5132e-01, -7.4411e-01,\n",
      "         9.7586e-01,  1.1774e-01, -1.8632e-01, -6.3294e-01, -1.4568e-01,\n",
      "        -1.1724e-01, -2.1556e+00, -1.9944e-01, -1.8806e-01,  1.7438e+00,\n",
      "        -2.7858e-01,  1.3734e-01, -1.8417e-01,  3.9119e-01, -2.2541e-02,\n",
      "         1.0445e-01,  1.1623e-01, -1.1707e-01,  1.6159e+00,  1.4887e-02,\n",
      "         6.9282e-01, -1.4228e+00,  9.0783e-01,  5.2608e-02,  5.2387e-01,\n",
      "        -1.8921e-01,  4.0898e-01, -2.8609e-01,  4.1768e-02, -1.0090e+00,\n",
      "        -1.1250e+00, -1.5890e+00,  2.2600e-01, -5.2789e-01, -1.1539e+00,\n",
      "         4.0163e-02,  7.6003e-01,  3.8240e-01, -6.2909e-01, -4.4434e-01,\n",
      "        -2.9347e-01,  6.3009e-01,  2.1753e-01, -8.8312e-01,  6.8326e-01,\n",
      "        -3.7501e-01,  8.7457e-01,  1.4691e-01,  3.3082e-01, -1.3296e-01,\n",
      "        -7.4006e-01,  2.6671e-01, -3.4132e-02,  5.1285e-01, -2.0125e-01,\n",
      "        -3.2923e-01, -1.0132e+00, -4.2411e-02, -5.5048e-01,  1.3034e+00,\n",
      "        -7.5541e-01,  1.1745e+00, -3.3792e-01,  6.9633e-01,  3.2435e-01,\n",
      "         1.4776e+00, -3.8719e-01, -2.0210e-01, -1.1106e+00, -1.1490e-01,\n",
      "        -6.9473e-01,  9.3014e-01, -6.6627e-01,  8.0281e-01, -8.1426e-01,\n",
      "        -3.7208e-03, -9.0090e-02, -1.4022e+00,  5.4445e-01,  3.6205e-02,\n",
      "         1.8221e-01,  3.4400e-01, -1.1155e+00,  3.1770e-01, -2.3610e+00,\n",
      "        -3.4943e-01,  1.2002e+00, -4.5046e-01, -2.3963e-01,  1.2948e+00,\n",
      "         8.8413e-01,  4.3471e-02,  1.5956e+00, -1.1640e+00,  8.8389e-01,\n",
      "         2.3434e-01, -3.8292e-01,  1.3525e-01,  5.7632e-01, -4.6966e-01,\n",
      "        -3.6175e-01,  5.6411e-01,  2.8903e-01, -1.5012e+00,  1.0205e+00,\n",
      "         7.9769e-02, -1.0532e-01,  1.1472e+00,  1.0829e-01,  2.4236e-01,\n",
      "        -1.2594e+00,  1.7669e-02,  1.4449e+00, -3.5810e-01, -7.0025e-01,\n",
      "        -4.0563e-01, -1.2009e+00, -8.5005e-01, -6.9804e-01,  6.0072e-01,\n",
      "         1.2629e+00,  1.9273e-01,  4.8392e-01,  3.4933e-02, -1.1214e+00,\n",
      "        -7.5637e-03, -3.9954e-02,  2.1938e-01,  5.7209e-01, -1.9333e+00,\n",
      "        -4.7357e-02, -1.0039e-01,  1.7071e+00, -2.9492e-01,  6.8191e-01,\n",
      "        -9.9072e-01,  3.3322e-01,  8.8557e-01, -3.2503e-01,  7.9406e-01,\n",
      "         3.0098e-01,  1.1523e+00, -1.4843e+00, -3.3230e-01,  5.1732e-01,\n",
      "        -3.4082e-01, -9.7633e-03,  1.9713e+00, -4.4575e-01,  1.7896e+00,\n",
      "        -2.7206e-01, -5.2720e-01,  1.1821e+00,  1.9529e-01,  1.1399e+00,\n",
      "        -3.5736e-02, -5.0217e-01, -6.4599e-03,  1.1104e+00,  3.9921e-01,\n",
      "         5.0864e-01, -5.1451e-02,  4.6868e-01,  2.5126e-01, -2.6609e-01,\n",
      "         8.9731e-01,  4.5597e-01, -8.2984e-01, -2.3784e-01, -7.5490e-01,\n",
      "         8.4517e-01, -1.1094e+00,  5.2155e-01,  8.0456e-01,  2.6603e-01,\n",
      "        -5.3744e-02, -3.4203e-01, -1.6606e-01,  5.8431e-01,  5.3517e-01,\n",
      "        -6.1654e-01, -2.6113e-01,  7.6848e-01, -8.6569e-01, -3.9976e-02,\n",
      "         7.7593e-01, -7.4135e-01, -1.3070e+00, -1.0050e-01,  9.2740e-01,\n",
      "        -4.3835e-01, -6.0427e-02,  1.6467e-01,  7.7504e-01, -1.3795e-01,\n",
      "         6.7970e-01,  2.3766e-01, -4.7561e-01,  3.4654e-01, -9.0687e-01,\n",
      "         4.8504e-01,  8.8580e-01,  3.5767e-01,  5.1188e-01, -4.9129e-01,\n",
      "        -4.1262e-01, -1.0223e+00, -2.8188e-01, -5.3648e-01, -1.0755e+00,\n",
      "        -1.4052e+00, -1.6066e+00,  2.1439e-01,  2.1296e-01, -1.0520e+00,\n",
      "         4.4983e-01, -9.4248e-01, -1.0383e+00,  6.5357e-01, -6.9267e-01,\n",
      "        -3.8974e-01,  4.2132e-01, -8.3326e-01, -3.7954e-01,  3.9915e-01,\n",
      "        -8.8183e-01, -2.8288e-01,  1.6779e-02, -6.6669e-01, -1.5923e-02,\n",
      "        -1.4775e+00,  5.5493e-01,  3.4602e-01,  4.4594e-02, -1.7094e+00,\n",
      "         1.3324e+00, -2.9309e-02, -1.9085e+00, -3.6933e-01, -2.2411e-01,\n",
      "        -7.1410e-01, -1.8093e+00, -3.5728e-01, -4.5517e-02, -3.9341e-01,\n",
      "        -1.5214e-01, -2.8053e-01,  5.6761e-01, -4.5750e-01,  6.5204e-01,\n",
      "         8.0884e-01,  1.0188e+00,  2.8381e-01,  3.2497e-03, -6.3118e-01,\n",
      "        -1.5537e+00, -1.0333e+00, -6.3246e-01,  3.8748e-01, -6.0589e-01,\n",
      "         4.9665e-01,  3.3884e-01, -8.3222e-02, -1.6326e+00, -2.7162e-01,\n",
      "         1.2001e-01,  1.4622e+00, -1.1324e-01,  1.1943e+00, -5.2408e-01,\n",
      "        -4.7042e-01, -1.7824e-01, -1.1279e+00,  8.7351e-01, -7.8044e-01,\n",
      "         4.1882e-01, -3.7073e-01, -1.5016e+00, -8.8678e-02, -5.2189e-02,\n",
      "        -5.9639e-01, -1.5120e+00,  1.1461e+00, -1.2217e+00,  9.8076e-01,\n",
      "         3.4118e-01,  3.5395e-01, -1.0061e+00, -1.5778e+00,  1.0295e-02,\n",
      "         1.6219e+00,  8.7222e-03, -6.8683e-01, -6.7790e-03, -1.0733e+00,\n",
      "         2.7922e-01, -2.6978e-01,  5.5063e-01,  9.8267e-01,  8.5488e-01,\n",
      "         5.1619e-01, -1.2940e+00,  5.8663e-01,  4.8408e-01, -2.2249e-01,\n",
      "        -1.2938e+00,  8.0875e-02,  3.3544e-01,  9.0617e-01, -3.6160e-01,\n",
      "         8.9465e-02,  2.3114e+00, -1.1396e+00, -2.5711e-02, -7.6020e-01,\n",
      "        -4.1007e-01, -5.6071e-01,  4.2982e-01,  6.0904e-01, -1.8076e+00,\n",
      "         6.0789e-01, -8.4048e-03, -4.2868e-01,  7.0945e-02,  6.1242e-01,\n",
      "        -2.8033e-01, -7.7927e-01, -1.1489e+00, -9.6332e-01, -1.8611e-01,\n",
      "         2.2650e-01,  6.7486e-01, -2.4308e-01,  6.6413e-01,  1.3065e-01,\n",
      "        -2.4797e-03,  7.2316e-02, -2.4857e-01, -8.3199e-02,  4.4572e-01,\n",
      "         9.5538e-01, -1.0279e+00, -1.2427e+00, -7.6626e-01,  1.1582e+00,\n",
      "         3.3964e-02,  6.4977e-01,  6.6219e-01,  9.8832e-01, -2.5642e-02,\n",
      "        -4.9901e-01, -2.6883e-01,  5.2306e-01, -7.3664e-01,  1.9521e-01,\n",
      "         1.1464e+00,  4.8449e-01,  3.5945e-01,  1.9874e-01,  1.5722e+00,\n",
      "        -1.9583e+00, -2.6184e-01,  8.3040e-01,  5.2430e-01, -6.2978e-01,\n",
      "        -9.0990e-01, -4.4570e-01,  3.5967e-01, -4.8814e-01, -1.3858e+00,\n",
      "        -5.7010e-01, -2.3094e-01, -1.8349e+00, -2.3037e-02, -5.3893e-01,\n",
      "        -4.0286e-01,  1.8188e+00, -2.4558e-01,  1.1959e-01,  8.0250e-01,\n",
      "         3.8207e-01,  5.0368e-01, -2.5784e-01,  5.8207e-01,  3.5521e-01,\n",
      "         1.1056e+00,  3.8815e-01, -1.4423e+00, -2.1024e-01, -6.3208e-01,\n",
      "         1.1035e-01, -1.7401e+00, -2.3643e-01,  5.0679e-01,  1.4888e+00,\n",
      "        -1.6701e+00, -5.2066e-01,  2.3233e-01,  1.0220e+00, -2.7078e-01,\n",
      "         9.2018e-01,  5.3767e-01,  3.8250e-01, -1.5744e-01, -3.8271e-01,\n",
      "         1.7479e-03,  9.7296e-01,  6.3517e-01,  5.1437e-01, -3.7645e-01,\n",
      "        -1.4407e+00,  2.7420e-01,  9.5657e-03,  1.2082e+00, -6.4432e-01,\n",
      "        -4.4620e-01,  1.7304e-01,  7.2010e-01,  1.7821e+00, -7.4224e-03,\n",
      "         9.7211e-01, -1.1116e-01, -1.0623e+00, -4.8159e-01, -2.1720e-01,\n",
      "        -1.5681e-01, -2.4420e-01, -3.3973e-03, -1.2884e+00, -2.0544e+00,\n",
      "         6.6473e-01, -9.5016e-02,  2.0535e-01, -1.6547e-01,  2.3728e-01,\n",
      "        -1.5628e+00, -1.0066e-01,  2.8704e-01, -6.3189e-01, -2.4159e-01,\n",
      "        -1.3890e-01,  3.1501e-01, -7.2165e-01, -1.6049e-01, -1.0237e+00,\n",
      "        -1.0694e-01,  9.1497e-01,  1.2277e+00,  3.6579e-01, -7.4847e-01,\n",
      "        -8.8772e-01,  8.9333e-01,  3.6891e-01,  1.5270e+00,  6.1981e-02,\n",
      "        -7.5813e-01,  9.6295e-01, -5.7816e-01,  1.7490e+00,  6.2879e-01,\n",
      "        -1.7439e-01,  1.2831e+00,  1.0270e+00,  6.0722e-01,  1.0183e-01,\n",
      "         1.4332e+00, -4.5399e-02,  8.0142e-01,  7.3016e-01,  7.2556e-02,\n",
      "        -8.4211e-02, -4.7940e-02,  2.8944e-01,  6.3138e-01, -6.2069e-01,\n",
      "        -9.9438e-01, -1.5938e+00,  8.9466e-01, -1.9935e+00, -2.4159e-01,\n",
      "        -2.4057e-01,  3.2946e-01,  1.3526e+00,  3.0716e-01, -2.5179e-01,\n",
      "        -1.9546e-01,  7.1547e-01, -5.8595e-01, -6.2493e-01, -7.8641e-02,\n",
      "         1.0981e+00,  2.7653e-01,  6.3106e-02, -6.9395e-02,  4.7339e-01,\n",
      "         8.3833e-02,  2.2402e+00,  3.2511e-01, -4.0779e-01,  7.8913e-01,\n",
      "         3.5265e-01,  7.2967e-01,  3.1291e-01,  1.8231e-01,  7.6842e-01,\n",
      "        -6.6008e-01,  3.6917e-01, -1.6330e+00, -3.5330e-01,  2.1746e-02,\n",
      "        -2.5180e-01, -3.1038e-01, -2.6711e-01, -6.5283e-01, -3.2874e-01,\n",
      "         7.5086e-02, -3.7205e-01, -2.9463e-01, -1.7468e+00, -9.2134e-01,\n",
      "         6.0693e-01, -5.9558e-01, -2.0261e-02, -6.0976e-01,  5.2707e-01,\n",
      "         9.1599e-01, -5.5397e-01,  1.2625e-01,  8.2749e-02,  1.9354e-01,\n",
      "        -6.8138e-01, -1.4345e+00, -1.1037e+00, -1.9924e-01,  4.9723e-01,\n",
      "         9.7547e-02,  1.5831e+00,  4.2385e-01, -5.5124e-01,  6.1925e-01,\n",
      "        -6.2489e-01,  1.7381e+00,  8.3101e-02,  7.5890e-01, -8.0969e-01,\n",
      "         1.3194e-01,  3.9024e-01, -2.0119e+00, -4.6007e-01,  2.1512e-01,\n",
      "         9.7570e-01,  1.0617e+00,  5.2445e-01,  4.7245e-01, -1.4049e+00,\n",
      "         3.5503e-02, -1.7805e-01,  1.0469e+00,  3.2534e-01, -2.3905e-01,\n",
      "        -1.3066e-01, -1.4483e+00,  2.1893e-01,  1.0304e+00, -2.4072e-02,\n",
      "        -2.4479e-01, -4.6379e-01, -9.4676e-01,  2.2339e+00, -1.2051e+00,\n",
      "         5.1751e-02, -6.0551e-01,  6.4160e-01,  1.0582e+00, -7.0608e-01,\n",
      "         1.5654e+00, -1.5796e-01, -1.7225e+00,  4.2301e-01, -2.2840e+00,\n",
      "         7.9659e-02,  8.2604e-01, -3.7253e-01, -2.7905e-01,  1.0290e+00,\n",
      "         7.5979e-01,  1.3553e-01,  5.0766e-01, -9.7758e-01,  7.0500e-03,\n",
      "         1.1288e+00,  6.7121e-01,  2.1436e-01,  1.2719e+00,  6.7857e-01,\n",
      "         4.8824e-01, -4.3368e-01, -6.3709e-01, -1.5695e+00,  2.3401e-01,\n",
      "        -7.0078e-01, -1.8648e-01,  1.1552e+00, -2.2021e+00,  2.3697e-01,\n",
      "         6.8709e-01, -8.3235e-01,  2.9035e-01,  1.7244e+00, -7.8213e-01,\n",
      "         2.7603e-01,  4.5181e-01, -3.1769e-01, -1.3961e+00,  5.9017e-01,\n",
      "         3.1998e-01, -1.1514e+00,  8.7129e-01,  2.3396e-01, -1.6085e+00,\n",
      "        -8.3303e-01, -2.8448e-01, -1.0919e+00, -2.1228e-02, -4.3567e-01,\n",
      "        -4.2898e-01, -4.4157e-01,  5.2939e-01])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAI/CAYAAABEVcwAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZEUlEQVR4nO3dfYxlB3nf8d9TFvIHQYXEyzvLRC2y\nRBA41cokKpWgEGK8CDcRabGqBBqiDVGQghQpWoIEVaJIW6EkVUMU5AYLUlEHpcQJ6poXN41kkIBg\nIwMGTHDQImwo5iXhpaSKHJ7+sXfNZDyzM547z9yZ8ecjjfbcc88955mzs+Ovz525t7o7AADsrX+y\n6gEAAI4ikQUAMEBkAQAMEFkAAANEFgDAAJEFADDg2KoH2Mxll13Wa2trqx4DAGBbt91221e7+/jG\n9QcystbW1nLrrbeuegwAgG1V1ec3W+/pQgCAASILAGCAyAIAGCCyAAAGiCwAgAEiCwBggMgCABgg\nsgAABogsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIAGCCyAAAGiCwAgAEiCwBggMgCABgg\nsgAABogsAIABIgsAYIDIAgAYILIAAAYcW/UAAMtYO3Nu0/Xnz54aOc5e7Xf93Hs9K3AwuJIFADBA\nZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAAkQUAMGDbV3yvquuTvDjJvd39jMW6dyS5\nfLHJo5P8bXdfscljzyf5VpJ/SHJfd5/co7kBAA60nbytzluTvCnJH15c0d3/7uJyVf1Wkm9c4vHP\n6+6v7nZAAIDDaNvI6u5bqmpts/uqqpL82yT/em/HAgA43Jb9max/leTL3f3ZLe7vJO+rqtuq6vSS\nxwIAODR28nThpVyb5IZL3P+c7r6nqh6b5OaqurO7b9lsw0WEnU6SEydOLDkWAMBq7fpKVlUdS/JT\nSd6x1Tbdfc/iz3uT3Jjkyktse113n+zuk8ePH9/tWAAAB8IyTxe+IMmd3X33ZndW1SOr6lEXl5O8\nMMkdSxwPAODQ2DayquqGJB9McnlV3V1Vr1zc9bJseKqwqp5YVTctbj4uyQeq6mNJ/jLJue5+z96N\nDgBwcO3ktwuv3WL9KzZZ98UkVy+WP5fkWUvOBwBwKHnFdwCAASILAGCAyAIAGCCyAAAGiCwAgAEi\nCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIAGCCyAAAGiCwAgAEi\nCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIAGCCyAAAGiCwAgAEi\nCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIAGHBs1QMAsLW1M+fu\nXz5/9tQKJwEeLFeyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACA\nASILAGCAyAIAGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACA\nASILAGDAtpFVVddX1b1Vdce6df+xqu6pqtsXH1dv8dirquozVXVXVZ3Zy8EBAA6ynVzJemuSqzZZ\n/zvdfcXi46aNd1bVw5L8XpIXJXl6kmur6unLDAsAcFhsG1ndfUuSr+9i31cmuau7P9fdf5/kj5Jc\ns4v9AAAcOsv8TNarq+rji6cTH7PJ/U9K8oV1t+9erAMAOPJ2G1m/n+SfJbkiyZeS/Nayg1TV6aq6\ntapu/cpXvrLs7gAAVmpXkdXdX+7uf+ju7yb5r7nw1OBG9yR5yrrbT16s22qf13X3ye4+efz48d2M\nBQBwYOwqsqrqCetu/mSSOzbZ7CNJnlZVP1RVj0jysiTv2s3xAAAOm2PbbVBVNyR5bpLLquruJG9I\n8tyquiJJJzmf5BcW2z4xyR9099XdfV9VvTrJe5M8LMn13f3Jkc8CAOCA2TayuvvaTVa/ZYttv5jk\n6nW3b0rygJd3AAA46rziOwDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAA\nkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAA\nkQUAMEBkAQAMEFkAAAOOrXoAgINm7cy5VY8AHAGuZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAA\nA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAA\nA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAw4NiqBwAOr7Uz\n5+5fPn/21Aon2dr6GS9aZtbNPufDcB6A/edKFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQB\nAAwQWQAAA0QWAMCAbSOrqq6vqnur6o51695YVXdW1cer6saqevQWjz1fVZ+oqtur6ta9HBwA4CDb\nyZWstya5asO6m5M8o7ufmeSvkrz2Eo9/Xndf0d0ndzciAMDhs21kdfctSb6+Yd37uvu+xc0PJXny\nwGwAAIfWXvxM1s8lefcW93WS91XVbVV1eg+OBQBwKBxb5sFV9bok9yV5+xabPKe776mqxya5uaru\nXFwZ22xfp5OcTpITJ04sMxYAwMrt+kpWVb0iyYuT/Pvu7s226e57Fn/em+TGJFdutb/uvq67T3b3\nyePHj+92LACAA2FXkVVVVyX51SQv6e7vbLHNI6vqUReXk7wwyR2bbQsAcNTs5CUcbkjywSSXV9Xd\nVfXKJG9K8qhceArw9qp682LbJ1bVTYuHPi7JB6rqY0n+Msm57n7PyGcBAHDAbPszWd197Sar37LF\ntl9McvVi+XNJnrXUdAAAh5RXfAcAGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDI\nAgAYILIAAAZs+7Y6wEPP2plz9y+fP3tqJcfbrxkuHmc/Ps+9stNzs3679Q7T5wqHmStZAAADRBYA\nwACRBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYA\nwACRBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYA\nwACRBQAw4NiqBwDg4Fg7c+7+5fNnT61wEjj8XMkCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaI\nLACAASILAGCAyAIAGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaI\nLACAASILAGCAyAIAGCCyAAAGiCwAgAEiCwBgwI4iq6qur6p7q+qOdet+oKpurqrPLv58zBaPffli\nm89W1cv3anAAgINsp1ey3prkqg3rziT58+5+WpI/X9z+R6rqB5K8Icmzk1yZ5A1bxRgAwFGyo8jq\n7luSfH3D6muSvG2x/LYk/2aTh/5Ekpu7++vd/TdJbs4DYw0A4MhZ5meyHtfdX1os/58kj9tkmycl\n+cK623cv1gEAHGnH9mIn3d1V1cvso6pOJzmdJCdOnNiLsYADbu3MuQe13fmzpybH2RN7Netm5+bB\nni9gtZa5kvXlqnpCkiz+vHeTbe5J8pR1t5+8WPcA3X1dd5/s7pPHjx9fYiwAgNVbJrLeleTibwu+\nPMmfbbLNe5O8sKoes/iB9xcu1gEAHGk7fQmHG5J8MMnlVXV3Vb0yydkkP15Vn03ygsXtVNXJqvqD\nJOnuryf5jSQfWXz8+mIdAMCRtqOfyerua7e46/mbbHtrkp9fd/v6JNfvajoAgEPKK74DAAwQWQAA\nA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAA\nA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAw4NiqBwAOh7Uz\n5+5fPn/21K4fv91j1x/noeagfe47/TsDNudKFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQB\nAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQB\nAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADjq16AICdWjtz7v7l\n82dPje170n4d58Haj7kuHmOrv7vt7ofDxpUsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIA\nGCCyAAAGiCwAgAG7jqyquryqbl/38c2qes2GbZ5bVd9Yt83rlx8ZAODg2/Xb6nT3Z5JckSRV9bAk\n9yS5cZNN39/dL97tcQAADqO9errw+Un+urs/v0f7AwA41PYqsl6W5IYt7vuxqvpYVb27qn54j44H\nAHCgLR1ZVfWIJC9J8seb3P3RJE/t7mcl+d0kf3qJ/Zyuqlur6tavfOUry44FALBSe3El60VJPtrd\nX954R3d/s7u/vVi+KcnDq+qyzXbS3dd198nuPnn8+PE9GAsAYHX2IrKuzRZPFVbV46uqFstXLo73\ntT04JgDAgbbr3y5Mkqp6ZJIfT/IL69a9Kkm6+81JXprkF6vqviR/l+Rl3d3LHBMA4DBYKrK6+/8m\n+cEN6968bvlNSd60zDEAAA4jr/gOADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAA\nkQUAMGCpV3wH9t/amXNJkvNnT614ksPr4jmc3M/6+w7q39Ven4edfp4P5tz4eucwcyULAGCAyAIA\nGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIA\nGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIA\nGCCyAAAGiCwAgAHHVj0AcMHamXNJkvNnTx34fV/c33brJj6XndpsnoNqmVl389jDdG52avLfD+yW\nK1kAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAM\nEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAM\nWDqyqup8VX2iqm6vqls3ub+q6r9U1V1V9fGq+hfLHhMA4KA7tkf7eV53f3WL+16U5GmLj2cn+f3F\nnwAAR9Z+PF14TZI/7As+lOTRVfWEfTguAMDK7EVkdZL3VdVtVXV6k/uflOQL627fvVgHAHBk7cXT\nhc/p7nuq6rFJbq6qO7v7lge7k0WgnU6SEydO7MFY8D1rZ87dv3z+7KkVTrK9nc667Od08fGT52P9\njJdad9Qdpc/5Ul83B+3f2WGalaNp6StZ3X3P4s97k9yY5MoNm9yT5Cnrbj95sW7jfq7r7pPdffL4\n8ePLjgUAsFJLRVZVPbKqHnVxOckLk9yxYbN3JfnZxW8Z/miSb3T3l5Y5LgDAQbfs04WPS3JjVV3c\n13/v7vdU1auSpLvfnOSmJFcnuSvJd5L8hyWPCQBw4C0VWd39uSTP2mT9m9ctd5JfWuY4AACHjVd8\nBwAYILIAAAaILACAASILAGCAyAIAGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYIDI\nAgAYILIAAAaILACAASILAGCAyAIAGCCyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsAYMCx\nVQ8AB9XamXNJkvNnT61s35MzXOp42607CA7qXEfRMud6v/+efF1wkLiSBQAwQGQBAAwQWQAAA0QW\nAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QW\nAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QW\nAMCAY6seAHZj7cy5JMn5s6d2tG6nj73UsTZa//hL7ftSLnXcZe1035MzcHRt93Wz119X6/d38d/X\nbo6x31/vD/Z7wmaP3e3jd7Lvvd7v9L4PG1eyAAAGiCwAgAEiCwBggMgCABggsgAABogsAIABIgsA\nYIDIAgAYILIAAAbsOrKq6ilV9RdV9amq+mRV/fIm2zy3qr5RVbcvPl6/3LgAAIfDMm+rc1+SX+nu\nj1bVo5LcVlU3d/enNmz3/u5+8RLHAQA4dHZ9Jau7v9TdH10sfyvJp5M8aa8GAwA4zPbkZ7Kqai3J\njyT58CZ3/1hVfayq3l1VP7wXxwMAOOiWebowSVJV35/knUle093f3HD3R5M8tbu/XVVXJ/nTJE/b\nYj+nk5xOkhMnTiw7FgDASi11JauqHp4LgfX27v6Tjfd39ze7+9uL5ZuSPLyqLttsX919XXef7O6T\nx48fX2YsAICVW+a3CyvJW5J8urt/e4ttHr/YLlV15eJ4X9vtMQEADotlni78l0l+Jsknqur2xbpf\nS3IiSbr7zUlemuQXq+q+JH+X5GXd3UscEwDgUNh1ZHX3B5LUNtu8KcmbdnsMAIDDyiu+AwAMEFkA\nAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAxY5m114AHWzpy7f/n82VMPWLfxvu32\ns367zfaz3QwHwV7Ms90+Duu5gd2Y/Dre7HvPTme41Pe83Xwf3MvHsxquZAEADBBZAAADRBYAwACR\nBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACR\nBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEFADBAZAEADBBZAAADRBYAwACR\nBQAw4NiqB1iVtTPnkiTnz55a8SR75+LnlGz+eV3qc17/2Evt48Ec78HabIaJx+y1zWY4CHPBYbAf\n/3622992M1z8/jb573qZ73+H6b9je/3fje2Os+pz40oWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEF\nADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA0QWAMAAkQUAMEBkAQAMEFkAAANEFgDAAJEF\nADBAZAEADBBZAAADRBYAwACRBQAwQGQBAAwQWQAAA5aKrKq6qqo+U1V3VdWZTe7/vqp6x+L+D1fV\n2jLHAwA4LHYdWVX1sCS/l+RFSZ6e5NqqevqGzV6Z5G+6+58n+Z0k/2m3xwMAOEyWuZJ1ZZK7uvtz\n3f33Sf4oyTUbtrkmydsWy/8jyfOrqpY4JgDAobBMZD0pyRfW3b57sW7Tbbr7viTfSPKDSxwTAOBQ\nqO7e3QOrXprkqu7++cXtn0ny7O5+9bpt7lhsc/fi9l8vtvnqJvs7neT04ublST6zq8G2dlmSBxyX\nMc73/nGu949zvX+c6/3jXC/vqd19fOPKY0vs8J4kT1l3+8mLdZttc3dVHUvyT5N8bbOddfd1Sa5b\nYp5Lqqpbu/vk1P75x5zv/eNc7x/nev841/vHuZ6zzNOFH0nytKr6oap6RJKXJXnXhm3eleTli+WX\nJvnfvdtLZwAAh8iur2R1931V9eok703ysCTXd/cnq+rXk9za3e9K8pYk/62q7kry9VwIMQCAI2+Z\npwvT3TcluWnDutevW/5/SX56mWPsobGnItmU871/nOv941zvH+d6/zjXQ3b9g+8AAGzN2+oAAAx4\nSEVWVf1GVX28qm6vqvdV1RNXPdNRVVVvrKo7F+f7xqp69KpnOqqq6qer6pNV9d2q8htCA7Z7CzH2\nTlVdX1X3Ll4CiEFV9ZSq+ouq+tTie8gvr3qmo+YhFVlJ3tjdz+zuK5L8zySv3+4B7NrNSZ7R3c9M\n8ldJXrvieY6yO5L8VJJbVj3IUbTDtxBj77w1yVWrHuIh4r4kv9LdT0/yo0l+ydf23npIRVZ3f3Pd\nzUcm8QNpQ7r7fYtX+U+SD+XC66gxoLs/3d17/eK9fM9O3kKMPdLdt+TCb6MzrLu/1N0fXSx/K8mn\n88B3bmEJS/124WFUVb+Z5Gdz4S1+nrficR4qfi7JO1Y9BOzSZm8h9uwVzQIjqmotyY8k+fBqJzla\njlxkVdX/SvL4Te56XXf/WXe/Lsnrquq1SV6d5A37OuARst25Xmzzuly4JP32/ZztqNnJuQbYjar6\n/iTvTPKaDc/4sKQjF1nd/YIdbvr2XHiNL5G1S9ud66p6RZIXJ3m+V/pfzoP4umbv7eQtxOBQqqqH\n50Jgvb27/2TV8xw1D6mfyaqqp627eU2SO1c1y1FXVVcl+dUkL+nu76x6HljCTt5CDA6dqqpceGeW\nT3f3b696nqPoIfVipFX1ziSXJ/luks8neVV3+z/SAYu3Uvq+fO8NwT/U3a9a4UhHVlX9ZJLfTXI8\nyd8mub27f2K1Ux0tVXV1kv+c772F2G+ueKQjq6puSPLcJJcl+XKSN3T3W1Y61BFVVc9J8v4kn8iF\n/y4mya8t3s2FPfCQiiwAgP3ykHq6EABgv4gsAIABIgsAYIDIAgAYILIAAAaILACAASILAGCAyAIA\nGPD/ASpMNQfxYpKkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_i = 6\n",
    "batch_i = 0\n",
    "layer_i = 6\n",
    "\n",
    "print(encoded_layers[layer_i][0].shape)\n",
    "\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "print(vec)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "['[CLS]', 'survival', 'wild', 'survival', 'tool', 'aid', 'touch', 'emergency', 'bag', 'earthquake', 'aid', 'bag', 'ur', '##lu', '##rl', 'ur', '##lu', '##rl', '[SEP]']\n",
      "453\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-6feb07150a4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#             print(layer_i,batch_i,token_i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#             print(encoded_layers[layer_i][batch_i].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mhidden_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "# print(len(txts_tokens[1]))\n",
    "# print(txts_tokens[1])\n",
    "# print(len(txts_tokens))\n",
    "# all_embeddings = []\n",
    "# for batch_i in range(0, len(txts_tokens)):\n",
    "#     for txt_tokens in txts_tokens:\n",
    "#         token_embeddings = []\n",
    "\n",
    "#     #     print(len(txt_tokens))\n",
    "#         for token_i in range(len(txt_tokens)):\n",
    "#             hidden_layers = [] \n",
    "#             for layer_i in range(len(encoded_layers)):\n",
    "#     #             print(layer_i,batch_i,token_i)\n",
    "#     #             print(encoded_layers[layer_i][batch_i].shape)\n",
    "#                 vec = encoded_layers[layer_i][batch_i][token_i]    \n",
    "#                 hidden_layers.append(vec)\n",
    "#             token_embeddings.append(hidden_layers)\n",
    "#         all_embeddings.append(token_embeddings)\n",
    "\n",
    "# # Sanity check the dimensions:\n",
    "# print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "# print (\"Number of layers per token:\", len(token_embeddings[0]))\n",
    "# print (\"Number of total embeddings:\", len(all_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated vector shape is: 2 x 3072\n",
      "Sum vector shape is: 2 x 768\n"
     ]
    }
   ],
   "source": [
    "# token_vecs_cat = []\n",
    "# token_vecs_sum = []\n",
    "\n",
    "# for token in token_embeddings:\n",
    "#     cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), 0)\n",
    "#     token_vecs_cat.append(cat_vec)\n",
    "#     sum_vec = torch.sum(torch.stack(token)[-4:], 0)\n",
    "#     token_vecs_sum.append(sum_vec)\n",
    "\n",
    "# print('Concatenated vector shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
    "# print('Sum vector shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2284, -0.0532,  0.4066,  ...,  0.0106,  0.1508, -0.3040],\n",
      "         [-0.0853, -0.4222,  0.6365,  ..., -0.5717,  0.1021, -0.3731],\n",
      "         [ 0.1465, -0.3322,  0.7312,  ..., -0.1375,  0.1943,  0.3347],\n",
      "         ...,\n",
      "         [ 0.0594, -0.2842,  0.9968,  ..., -0.5556,  0.0894, -0.6480],\n",
      "         [ 0.0696, -0.2859,  1.0168,  ..., -0.5726,  0.1498, -0.6146],\n",
      "         [ 0.0638, -0.2205,  0.9603,  ..., -0.5755,  0.1049, -0.6666]]])\n",
      "torch.Size([1, 64, 768])\n",
      "Our final sentence embedding vector of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, torch.Size([1, 768]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate sentence lavel vector by averaging the second to last hidden layer of each token producing a single 768 length vector.\n",
    "all_sentences_embedding = []\n",
    "\n",
    "for batch_i in range(len(txts_tokens)):\n",
    "    all_sentences_embedding.append(torch.mean(all_encoded_layers[batch_i][11], 1))\n",
    "\n",
    "print(len(all_sentences_embedding))\n",
    "\n",
    "print (\"Count of sentence embeddings found:\",len(all_sentences_embedding))\n",
    "print (\"Single sentence embedding vector of shape:\",all_sentences_embedding[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def knn_lbl_majority(test_features,train_features,train_labels,k=5):\n",
    "\n",
    "#     from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#     NN = KNeighborsClassifier(n_neighbors=k)\n",
    "#     NN.fit(train_features,train_labels)\n",
    "#     test_labels = NN.predict(test_features)\n",
    "#     ## To get probabilities: test_labels_probas = NN.predict_proba(test_features)\n",
    "#     return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighrest_neighbors(test_features,train_features,n,k=2):\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "    NN = NearestNeighbors(n_neighbors=k)\n",
    "    NN.fit(train_features)\n",
    "    closest_neighbors_from_train = NN.kneighbors(test_features,\n",
    "    return_distance=False)\n",
    "    return closest_neighbors_from_train[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4d87213a3d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df_bert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxts_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxts_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_features = test_df_bert['tweets']\n",
    "train_features = \n",
    "train_labels = txts_tokens['labels']\n",
    "n=2\n",
    "n_idxs = neighrest_neighbors(test_features, train_features, n)\n",
    "count = np.zeros(4)\n",
    "#n is for precision at k\n",
    "print(test_features)\n",
    "print(train_features)\n",
    "print(train_labels)\n",
    "for ii in n_idxs:\n",
    "    count = np.zeros(4)\n",
    "    for l in range(0,n):\n",
    "        for i in n_idxs[l]:\n",
    "            for j in train_labels[i]:\n",
    "                count[j] = count[j] + 1\n",
    "\n",
    "    \n",
    "    print(np.argsort(count)[4-n:])\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# print(test_labels[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}